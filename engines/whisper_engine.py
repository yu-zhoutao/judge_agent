import os
import io
import time
import json
import uuid
import wave
import math
import base64
import requests
import subprocess
import imageio_ffmpeg
import urllib3
from typing import List, Dict, Any, Tuple
from multiprocessing.pool import ThreadPool
from judge_agent.config import Config

# å±è”½ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class WhisperEngine:
    """
    åœ¨çº¿ ASR è¯­éŸ³è½¬å†™å¼•æ“ (å¹¶å‘ç‰ˆ)
    é›†æˆéŸ³é¢‘è½¬ç ã€åˆ‡ç‰‡ã€å¹¶å‘è¯·æ±‚ä¸ç»“æœåˆå¹¶
    """

    @classmethod
    def _convert_to_16k_wav(cls, source_path: str) -> str:
        """
        ä½¿ç”¨ FFmpeg å°†ä»»æ„éŸ³é¢‘/è§†é¢‘è½¬æ¢ä¸º 16ké‡‡æ ·ç‡ã€å•å£°é“ WAV
        """
        if not os.path.exists(Config.FIXED_TEMP_DIR):
            os.makedirs(Config.FIXED_TEMP_DIR)

        filename = f"temp_asr_{uuid.uuid4().hex[:8]}.wav"
        output_path = os.path.join(Config.FIXED_TEMP_DIR, filename)
        ffmpeg_exe = imageio_ffmpeg.get_ffmpeg_exe()

        # -ar 16000: é‡‡æ ·ç‡ 16k
        # -ac 1: å•å£°é“
        # -c:a pcm_s16le: 16ä½ PCM ç¼–ç 
        cmd = [
            ffmpeg_exe, '-y',
            '-i', source_path,
            '-ar', '16000',
            '-ac', '1',
            '-c:a', 'pcm_s16le',
            output_path
        ]

        try:
            subprocess.run(
                cmd,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.PIPE,
                check=True
            )
            return output_path
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"éŸ³é¢‘è½¬ç å¤±è´¥: {e.stderr.decode() if e.stderr else 'unknown error'}")

    @classmethod
    def _split_wav(cls, byte_data: bytes, segment_length=60):
        """
        å°† WAV äºŒè¿›åˆ¶æ•°æ®æŒ‰æ—¶é•¿åˆ‡ç‰‡
        :param segment_length: åˆ‡ç‰‡æ—¶é•¿(ç§’)ï¼Œé»˜è®¤ 60s
        """
        wf = wave.open(io.BytesIO(byte_data), "rb")
        nchannels = wf.getnchannels()
        sampwidth = wf.getsampwidth()
        framerate = wf.getframerate()
        nframes = wf.getnframes()

        duration = nframes / framerate
        data_length = int(segment_length * framerate)  # å¿…é¡»è½¬ä¸º int

        segments = []
        # è®¡ç®—åˆ‡ç‰‡æ•°é‡
        num_chunks = math.ceil(1.0 * duration / segment_length)

        for i in range(num_chunks):
            wf.setpos(i * data_length)
            data = wf.readframes(data_length)

            tmpf = io.BytesIO()
            with wave.open(tmpf, "wb") as new_wf:
                new_wf.setnchannels(nchannels)
                new_wf.setsampwidth(sampwidth)
                new_wf.setframerate(framerate)
                new_wf.writeframes(data)

            segments.append(tmpf.getvalue())

        wf.close()
        return segments, duration

    @classmethod
    def _asr_infer(cls, task: Dict[str, Any]) -> Dict[str, Any]:
        """
        å•æ¬¡ API è¯·æ±‚ä»»åŠ¡
        """
        try:
            bdata = task["bdata"]
            url = Config.ASR_API_URL

            # æ„é€  Payload
            payload = {
                "request_id": f"req_{uuid.uuid4().hex[:8]}",
                "audio_type": "wav",
                "audio_data": base64.b64encode(bdata).decode(),
                "stream": False,
                "audio_fs": 16000
            }

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {Config.ASR_API_KEY}",
                "Connection": "keep-alive",
            }

            # å‘èµ·è¯·æ±‚ (åŒ…å« SSL è·³è¿‡å’Œå†…ç½‘ä»£ç†è®¾ç½®)
            # debug_st = time.time()
            resp = requests.post(
                url,
                headers=headers,
                json=payload,
                verify=False,
                proxies={"http": None, "https": None},
                timeout=60
            )
            # print(f"Chunk processed in {time.time() - debug_st:.2f}s")

            if resp.status_code != 200:
                print(f"âŒ ASR Chunk Failed: {resp.status_code} - {resp.text[:100]}")
                return {}

            jsres = resp.json()
            # æå–ç»“æœï¼Œä¸åŒ API ç»“æ„å¯èƒ½ç•¥æœ‰ä¸åŒï¼Œè¿™é‡Œæ²¿ç”¨å‚è€ƒä»£ç çš„è·¯å¾„
            # å‡è®¾ç»“æ„: {"result": {"result": [{"text":..., "timestamp":...}]}}
            if "result" in jsres and "result" in jsres["result"]:
                result_list = jsres["result"]["result"]
                if result_list:
                    result = result_list[0]
                    # ä¿®æ­£ç›¸å¯¹æ—¶é—´æˆ³ä¸ºç»å¯¹æ—¶é—´æˆ³ (APIè¿”å›çš„æ˜¯åˆ†ç‰‡å†…çš„åç§»ï¼Œéœ€è¦åŠ ä¸Šåˆ‡ç‰‡èµ·å§‹æ—¶é—´)
                    # æ³¨æ„ï¼šå‚è€ƒä»£ç ä¸­ task["bg"] æ˜¯ç§’ï¼Œè¿™é‡Œè½¬ä¸ºæ¯«ç§’
                    result["start"] = task["bg"] * 1000
                    return result

            return {}

        except Exception as e:
            print(f"âŒ ASR Infer Exception: {e}")
            return {}

    @classmethod
    def _merge_asr_results(cls, results: List[Dict], punctuation="ã€‚ï¼ï¼Ÿï¼›ï¼Œã€", ts_unit="ms"):
        """
        åˆå¹¶ç»“æœå¹¶æ ¹æ®æ ‡ç‚¹ç¬¦å·è¿›è¡Œæ–­å¥
        """
        full_text = ""
        timestamp_list = []  # [[start, end], ...]
        segments = []  # [{"start":, "end":, "text":}, ...]

        # 1. æ‰å¹³åŒ–åˆå¹¶æ‰€æœ‰åˆ†ç‰‡çš„æ–‡æœ¬å’Œæ—¶é—´æˆ³
        # æŒ‰ç…§ start æ—¶é—´æ’åºï¼Œé˜²æ­¢çº¿ç¨‹ä¹±åº
        sorted_results = sorted([r for r in results if r], key=lambda x: x.get("start", 0))

        def to_sec(t):
            # å°†æ¯«ç§’è½¬ä¸ºç§’
            return float(t) / 1000.0 if ts_unit == "ms" else float(t)

        for r in sorted_results:
            full_text += r.get("text", "")

            # å¤„ç†æ¯ä¸€ä¸ªå­—çš„æ—¶é—´æˆ³
            chunk_start_ms = r.get("start", 0)
            for t in r.get("timestamp", []):
                # t[0], t[1] æ˜¯ç›¸å¯¹äºè¯¥åˆ†ç‰‡èµ·å§‹çš„åç§»é‡
                t_start = to_sec(t[0] + chunk_start_ms)
                t_end = to_sec(t[1] + chunk_start_ms)
                timestamp_list.append([t_start, t_end])

        # 2. æ ¹æ®æ ‡ç‚¹ç¬¦å·é‡æ–°åˆ‡åˆ†å¥å­ (Logic from reference)
        current_sentence = ""
        sent_start = None
        ts_idx = 0

        # éå†å…¨æ–‡å­—ç¬¦
        for char in full_text:
            if ts_idx < len(timestamp_list):
                if sent_start is None:
                    sent_start = timestamp_list[ts_idx][0]
                sent_end = timestamp_list[ts_idx][1]
                ts_idx += 1
            else:
                # å®¹é”™ï¼šæ–‡å­—æ¯”æ—¶é—´æˆ³å¤š
                if sent_start is None: sent_start = 0.0
                sent_end = sent_start

            current_sentence += char

            # é‡åˆ°æ ‡ç‚¹ï¼Œç»“æŸå½“å‰å¥
            if char in punctuation:
                clean_sentence = current_sentence.strip()
                if clean_sentence:
                    segments.append({
                        "start": round(sent_start, 2),
                        "end": round(sent_end, 2),
                        "text": clean_sentence
                    })
                current_sentence = ""
                sent_start = None

        # å¤„ç†æœ«å°¾å‰©ä½™æ–‡æœ¬
        if current_sentence.strip():
            segments.append({
                "start": round(sent_start if sent_start else 0.0, 2),
                "end": round(sent_end if sent_end else 0.0, 2),
                "text": current_sentence.strip()
            })

        return full_text, segments

    @classmethod
    def transcribe(cls, audio_path: str) -> Tuple[str, List[Dict[str, Any]]]:
        """
        ä¸»å…¥å£ï¼šæ‰§è¡ŒéŸ³é¢‘è½¬å†™
        :return: (å®Œæ•´æ–‡æœ¬, è¯¦ç»†åˆ†æ®µåˆ—è¡¨)
        """
        wav_path = None
        try:
            # 1. æ ¼å¼è½¬æ¢ (è½¬ä¸º 16k WAV)
            # print(f"ğŸ”„ æ­£åœ¨è½¬æ¢éŸ³é¢‘: {os.path.basename(audio_path)}")
            wav_path = cls._convert_to_16k_wav(audio_path)

            # 2. è¯»å–äºŒè¿›åˆ¶æ•°æ®
            with open(wav_path, "rb") as f:
                wav_bytes = f.read()

            # 3. åˆ‡ç‰‡ (æ¯ 60 ç§’ä¸€ç‰‡)
            segment_length = 60
            wav_chunks, duration = cls._split_wav(wav_bytes, segment_length)

            # 4. æ„é€ ä»»åŠ¡åˆ—è¡¨
            tasks = []
            for i, chunk_data in enumerate(wav_chunks):
                tasks.append({
                    "bg": i * segment_length,  # è¿™é‡Œçš„ bg å•ä½æ˜¯ç§’
                    "ed": min((i + 1) * segment_length, duration),
                    "bdata": chunk_data
                })

            # 5. å¹¶å‘è¯·æ±‚
            pool_size = min(len(tasks), Config.ASR_THREAD_POOL_SIZE)
            # print(f"ğŸš€ å¼€å§‹å¹¶å‘è¯†åˆ«: {len(tasks)} ä¸ªåˆ†ç‰‡, çº¿ç¨‹æ•°: {pool_size}")

            with ThreadPool(pool_size) as p:
                raw_results = p.map(cls._asr_infer, tasks)

            # 6. åˆå¹¶ç»“æœ
            full_text, segments = cls._merge_asr_results(raw_results)

            return full_text, segments

        except Exception as e:
            print(f"âŒ ASR è½¬å†™å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return "", []

        finally:
            # 7. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if wav_path and os.path.exists(wav_path):
                try:
                    os.remove(wav_path)
                except:
                    pass

    @classmethod
    def format_segments_for_llm(cls, segments: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–ä¸º LLM æ˜“è¯»çš„å­—ç¬¦ä¸²"""
        formatted = []
        for s in segments:
            formatted.append(f"[{s['start']} - {s['end']}] {s['text']}")
        return "\n".join(formatted)